{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection Framework Demo\n",
    "\n",
    "This notebook provides an end-to-end demonstration of three anomaly detection techniques on two distinct datasets: financial transactions and IoT sensor readings.\n",
    "\n",
    "**Models Used:**\n",
    "1. **Isolation Forest**\n",
    "2. **Local Outlier Factor (LOF)**\n",
    "3. **Autoencoder (Deep Learning)**\n",
    "\n",
    "**Workflow:**\n",
    "1. **Load & Prepare Data:** Use custom utility functions to load and scale both datasets.\n",
    "2. **Run Models:** Apply each anomaly detection model to the prepared data.\n",
    "3. **Analyze Results:** Identify the top anomalies flagged by each model and inspect their characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add the src directory to the Python path to import our modules\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_utils import load_and_prepare_finance_data, load_and_prepare_iot_data\n",
    "from anomaly_models import (\n",
    "    run_isolation_forest,\n",
    "    run_local_outlier_factor,\n",
    "    build_autoencoder,\n",
    "    get_reconstruction_errors\n",
    ")\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load financial data\n",
    "finance_df, X_finance = load_and_prepare_finance_data('../data/finance_transactions.csv')\n",
    "print(\"Financial Data Shape:\", X_finance.shape)\n",
    "display(finance_df.head())\n",
    "\n",
    "# Load IoT data\n",
    "iot_df, X_iot = load_and_prepare_iot_data('../data/iot_sensor_readings.csv')\n",
    "print(\"\\nIoT Data Shape:\", X_iot.shape)\n",
    "display(iot_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model 1: Isolation Forest on Financial Data\n",
    "\n",
    "Isolation Forest is efficient for high-dimensional data. We will apply it to the financial transaction data to find the most suspicious transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get anomaly scores\n",
    "finance_df['anomaly_score_isoforest'] = run_isolation_forest(X_finance)\n",
    "\n",
    "# Inspect the top 10 most anomalous transactions\n",
    "top_anomalies_isoforest = finance_df.sort_values(by='anomaly_score_isoforest', ascending=False)\n",
    "print(\"Top 10 Anomalies (Isolation Forest):\")\n",
    "display(top_anomalies_isoforest.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model 2: Local Outlier Factor (LOF) on IoT Data\n",
    "\n",
    "LOF is great at finding anomalies in datasets where the density varies. We will use it on the IoT sensor data to identify potential equipment faults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get anomaly flags (-1 for anomaly, 1 for normal)\n",
    "iot_df['anomaly_flag_lof'] = run_local_outlier_factor(X_iot)\n",
    "\n",
    "# Inspect all flagged anomalies\n",
    "anomalies_lof = iot_df[iot_df['anomaly_flag_lof'] == -1]\n",
    "print(f\"Total Anomalies Found (LOF): {len(anomalies_lof)}\")\n",
    "display(anomalies_lof.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model 3: Autoencoder on Financial Data\n",
    "\n",
    "Autoencoders learn to reconstruct normal data. Anomalies will have a high reconstruction error. We will train an autoencoder on the financial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train the autoencoder\n",
    "autoencoder = build_autoencoder(input_dim=X_finance.shape[1])\n",
    "history = autoencoder.fit(\n",
    "    X_finance, X_finance,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reconstruction errors\n",
    "finance_df['reconstruction_error'] = get_reconstruction_errors(autoencoder, X_finance)\n",
    "\n",
    "# Plot the distribution of errors\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(finance_df['reconstruction_error'], bins=50, kde=True)\n",
    "plt.title('Distribution of Reconstruction Errors')\n",
    "plt.show()\n",
    "\n",
    "# Inspect the top 10 anomalies based on reconstruction error\n",
    "top_anomalies_autoencoder = finance_df.sort_values(by='reconstruction_error', ascending=False)\n",
    "print(\"Top 10 Anomalies (Autoencoder):\")\n",
    "display(top_anomalies_autoencoder.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}